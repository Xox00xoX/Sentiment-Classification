import pandas as pd
import numpy as np
import tensorflow as tf
from transformers import ElectraTokenizer, TFElectraForSequenceClassification, create_optimizer
from sklearn.model_selection import train_test_split
import os

print("ğŸ“¦ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘...")
df = pd.read_csv("./data/cleaned_reviews_strong.csv").dropna(subset=["cleaned", "label"])
train_texts, val_texts, train_labels, val_labels = train_test_split(
    df["cleaned"], df["label"], test_size=0.2, random_state=42
)
print(f"âœ”ï¸ ì´ ë°ì´í„° ìˆ˜: {len(df)}, í•™ìŠµ: {len(train_texts)}, ê²€ì¦: {len(val_texts)}")

print("ğŸ”‘ í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...")
model_name = "monologg/koelectra-base-v3-discriminator"
tokenizer = ElectraTokenizer.from_pretrained(model_name)

MAX_LEN = 128
BATCH_SIZE = 24

print("ğŸ”¤ Tokenizing train ë°ì´í„°...")
train_encodings = tokenizer(
    list(train_texts), truncation=True, padding=True, max_length=MAX_LEN, return_tensors="tf"
)
print("âœ… train tokenizing ì™„ë£Œ")

print("ğŸ”¤ Tokenizing validation ë°ì´í„°...")
val_encodings = tokenizer(
    list(val_texts), truncation=True, padding=True, max_length=MAX_LEN, return_tensors="tf"
)
print("âœ… validation tokenizing ì™„ë£Œ")

print("ğŸ“ TF Dataset ìƒì„± ì¤‘...")
train_dataset = tf.data.Dataset.from_tensor_slices((
    dict(train_encodings),
    train_labels.values
)).shuffle(10000).batch(BATCH_SIZE)

val_dataset = tf.data.Dataset.from_tensor_slices((
    dict(val_encodings),
    val_labels.values
)).batch(BATCH_SIZE)
print("âœ… TF Dataset ìƒì„± ì™„ë£Œ")

print("ğŸ§  ëª¨ë¸ ë¡œë”© (PyTorch â†’ TensorFlow ë³€í™˜)...")
model = TFElectraForSequenceClassification.from_pretrained(
    model_name,
    num_labels=3,
    from_pt=True
)

print("âš™ï¸ ì˜µí‹°ë§ˆì´ì € ì„¤ì • ì¤‘...")
num_train_steps = len(train_dataset) * 3  # 3 epochs
optimizer, schedule = create_optimizer(init_lr=5e-5, num_train_steps=num_train_steps, num_warmup_steps=0)

print("ğŸ”§ ëª¨ë¸ ì»´íŒŒì¼ ì¤‘...")
model.compile(
    optimizer=optimizer,
    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
    metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]
)

# âœ… GPU ë©”ëª¨ë¦¬ ë™ì  í• ë‹¹ ì„¤ì •
print("ğŸ§  GPU ë©”ëª¨ë¦¬ ì„¤ì • ì¤‘...")
gpus = tf.config.experimental.list_physical_devices('GPU')
if gpus:
    try:
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("âœ… GPU ë©”ëª¨ë¦¬ ë™ì  í• ë‹¹ ì„¤ì • ì™„ë£Œ")
    except RuntimeError as e:
        print(f"âŒ ë©”ëª¨ë¦¬ ì„¤ì • ì˜¤ë¥˜: {e}")

print("ğŸš€ í•™ìŠµ ì‹œì‘!")
model.fit(train_dataset, validation_data=val_dataset, epochs=3)

print("ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘...")
model.save_pretrained("./models/koelectra_sentiment_model_tf")
tokenizer.save_pretrained("./models/koelectra_sentiment_model_tf")
print("âœ… ì €ì¥ ì™„ë£Œ")
